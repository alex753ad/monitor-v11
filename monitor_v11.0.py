"""
Pairs Position Monitor v5.3
v5.3: Hurst warning fix (threshold 0.48), full open positions CSV
v5.2: Full Open Pos CSV, adaptive stop, MTF sync

Ğ—Ğ°Ğ¿ÑƒÑĞº: streamlit run pairs_position_monitor.py
"""

import streamlit as st
import pandas as pd
import numpy as np
import ccxt
import time
import json
import os
from datetime import datetime, timedelta, timezone

MSK = timezone(timedelta(hours=3))
def now_msk():
    return datetime.now(MSK)
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from statsmodels.tsa.stattools import coint

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DRY: Import shared utilities from analysis module
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
try:
    from mean_reversion_analysis import (
        calculate_hurst_exponent,
        calculate_hurst_ema,
        calculate_adaptive_robust_zscore,
        calculate_garch_zscore,
        calc_halflife_from_spread,
        assess_entry_readiness,
        check_pnl_z_disagreement,
    )
    _USE_MRA = True
except ImportError:
    _USE_MRA = False

# v5.3: assess_entry_readiness â€” imported from analysis module when available
# Local fallback always defined (used when analysis module unavailable)

def assess_entry_readiness(p):
    """
    v8.0: Ğ•Ğ´Ğ¸Ğ½Ğ°Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ° Ñ HARD HURST GATE.
    Hurst â‰¥ 0.45 â†’ max Ğ£Ğ¡Ğ›ĞĞ’ĞĞ. Hurst=0.500 fallback â†’ max Ğ¡Ğ›ĞĞ‘Ğ«Ğ™.
    """
    mandatory = [
        ('Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ â‰¥ READY', p.get('signal', 'NEUTRAL') in ('SIGNAL', 'READY'), p.get('signal', 'NEUTRAL')),
        ('|Z| â‰¥ Thr', abs(p.get('zscore', 0)) >= p.get('threshold', 2.0),
         f"|{p.get('zscore',0):.2f}| vs {p.get('threshold',2.0)}"),
        ('Q â‰¥ 50', p.get('quality_score', 0) >= 50, f"Q={p.get('quality_score', 0)}"),
        ('Dir â‰  NONE', p.get('direction', 'NONE') != 'NONE', p.get('direction', 'NONE')),
    ]
    all_mandatory = all(m[1] for m in mandatory)
    
    fdr_ok = p.get('fdr_passed', False)
    stab_ok = p.get('stability_passed', 0) >= 3
    hurst_val = p.get('hurst', 0.5)
    hurst_ok = hurst_val < 0.35
    hurst_is_fallback = hurst_val == 0.5
    
    optional = [
        ('FDR âœ…', fdr_ok, 'âœ…' if fdr_ok else 'âŒ'),
        ('Conf=HIGH', p.get('confidence', 'LOW') == 'HIGH', p.get('confidence', 'LOW')),
        ('S â‰¥ 60', p.get('signal_score', 0) >= 60, f"S={p.get('signal_score', 0)}"),
        ('Ï â‰¥ 0.5', p.get('correlation', 0) >= 0.5, f"Ï={p.get('correlation', 0):.2f}"),
        ('Stab â‰¥ 3/4', stab_ok, f"{p.get('stability_passed',0)}/{p.get('stability_total',4)}"),
        ('Hurst < 0.35', hurst_ok, f"H={hurst_val:.3f}"),
    ]
    opt_count = sum(1 for _, met, _ in optional if met)
    fdr_bypass = (not fdr_ok and p.get('quality_score', 0) >= 70 and
                  stab_ok and p.get('adf_passed', False) and hurst_ok)
    
    if all_mandatory:
        if hurst_is_fallback:
            level, label = 'CONDITIONAL', 'ğŸŸ¡ Ğ¡Ğ›ĞĞ‘Ğ«Ğ™ âš ï¸H=0.5'
        elif hurst_val >= 0.45:
            level, label = 'CONDITIONAL', 'ğŸŸ¡ Ğ£Ğ¡Ğ›ĞĞ’ĞĞ âš ï¸Hâ‰¥0.45'
        elif opt_count >= 4:
            level, label = 'ENTRY', 'ğŸŸ¢ Ğ’Ğ¥ĞĞ”'
        elif opt_count >= 2 or fdr_bypass:
            level, label = 'CONDITIONAL', 'ğŸŸ¡ Ğ£Ğ¡Ğ›ĞĞ’ĞĞ'
        else:
            level, label = 'CONDITIONAL', 'ğŸŸ¡ Ğ¡Ğ›ĞĞ‘Ğ«Ğ™'
    else:
        level, label = 'WAIT', 'âšª Ğ–Ğ”ĞĞ¢Ğ¬'
    
    return {'level': level, 'label': label, 'all_mandatory': all_mandatory,
            'mandatory': mandatory, 'optional': optional,
            'fdr_bypass': fdr_bypass, 'opt_count': opt_count}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CORE MATH (standalone â€” Ğ½Ğµ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ñ‚ Ğ¾Ñ‚ analysis module)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def kalman_hr(s1, s2, delta=1e-4, ve=1e-3):
    s1, s2 = np.array(s1, float), np.array(s2, float)
    n = min(len(s1), len(s2))
    if n < 10: return None
    s1, s2 = s1[:n], s2[:n]
    init_n = min(30, n // 3)
    try:
        X = np.column_stack([np.ones(init_n), s2[:init_n]])
        beta = np.linalg.lstsq(X, s1[:init_n], rcond=None)[0]
    except: beta = np.array([0.0, 1.0])
    P = np.eye(2); Q = np.eye(2) * delta; R = ve
    hrs, ints, spread = np.zeros(n), np.zeros(n), np.zeros(n)
    for t in range(n):
        x = np.array([1.0, s2[t]]); P += Q
        e = s1[t] - x @ beta; S = x @ P @ x + R
        K = P @ x / S; beta += K * e
        P -= np.outer(K, x) @ P; P = (P + P.T) / 2
        np.fill_diagonal(P, np.maximum(np.diag(P), 1e-10))
        hrs[t], ints[t] = beta[1], beta[0]
        spread[t] = s1[t] - beta[1] * s2[t] - beta[0]
    return {'hrs': hrs, 'intercepts': ints, 'spread': spread,
            'hr': float(hrs[-1]), 'intercept': float(ints[-1])}


def calc_zscore(spread, halflife_bars=None, min_w=10, max_w=60):
    spread = np.array(spread, float); n = len(spread)
    if halflife_bars and not np.isinf(halflife_bars) and halflife_bars > 0:
        w = int(np.clip(2.5 * halflife_bars, min_w, max_w))
    else: w = 30
    w = min(w, max(10, n // 2))
    zs = np.full(n, np.nan)
    for i in range(w, n):
        lb = spread[i - w:i]; med = np.median(lb)
        mad = np.median(np.abs(lb - med)) * 1.4826
        if mad < 1e-10:
            s = np.std(lb)
            zs[i] = (spread[i] - np.mean(lb)) / s if s > 1e-10 else 0
        else: zs[i] = (spread[i] - med) / mad
    return zs, w


def calc_halflife(spread, dt=None):
    """OU halflife Ñ‡ĞµÑ€ĞµĞ· Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ñ. dt=1/24 Ğ´Ğ»Ñ 1h, 1/6 Ğ´Ğ»Ñ 4h, 1 Ğ´Ğ»Ñ 1d."""
    s = np.array(spread, float)
    if len(s) < 20: return 999
    sl, sd = s[:-1], np.diff(s)
    n = len(sl)
    sx, sy = np.sum(sl), np.sum(sd)
    sxy, sx2 = np.sum(sl * sd), np.sum(sl**2)
    denom = n * sx2 - sx**2
    if abs(denom) < 1e-10: return 999
    b = (n * sxy - sx * sy) / denom
    if dt is None: dt = 1.0
    theta = max(0.001, min(10.0, -b / dt))
    hl = np.log(2) / theta  # Ğ² ĞµĞ´Ğ¸Ğ½Ğ¸Ñ†Ğ°Ñ… dt
    return float(hl) if hl < 999 else 999


def calc_hurst(series, min_window=8):
    """DFA Hurst exponent (ÑƒĞ¿Ñ€Ğ¾Ñ‰Ñ‘Ğ½Ğ½Ñ‹Ğ¹, ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ñ‹Ğ¹ Ñ ÑĞºĞ°Ğ½ĞµÑ€Ğ¾Ğ¼)."""
    x = np.array(series, float)
    x = x[~np.isnan(x)]
    n = len(x)
    if n < 50: return 0.5
    
    y = np.cumsum(x - np.mean(x))
    
    scales = []
    flucts = []
    min_seg = max(min_window, 4)
    max_seg = n // 4
    
    for seg_len in range(min_seg, max_seg + 1, max(1, (max_seg - min_seg) // 20)):
        n_segs = n // seg_len
        if n_segs < 2: continue
        f2_list = []
        for i in range(n_segs):
            seg = y[i * seg_len:(i + 1) * seg_len]
            t = np.arange(len(seg))
            if len(seg) < 2: continue
            coeffs = np.polyfit(t, seg, 1)
            trend = np.polyval(coeffs, t)
            f2_list.append(np.mean((seg - trend) ** 2))
        if f2_list:
            scales.append(seg_len)
            flucts.append(np.sqrt(np.mean(f2_list)))
    
    if len(scales) < 4: return 0.5
    
    log_s = np.log(scales)
    log_f = np.log(np.array(flucts) + 1e-10)
    coeffs = np.polyfit(log_s, log_f, 1)
    
    # RÂ² check
    pred = np.polyval(coeffs, log_s)
    ss_res = np.sum((log_f - pred) ** 2)
    ss_tot = np.sum((log_f - np.mean(log_f)) ** 2)
    r_sq = 1 - ss_res / ss_tot if ss_tot > 0 else 0
    
    if r_sq < 0.8: return 0.5  # fallback
    return float(np.clip(coeffs[0], 0.01, 0.99))


def calc_correlation(p1, p2, window=60):
    """Rolling ĞºĞ¾Ñ€Ñ€ĞµĞ»ÑÑ†Ğ¸Ñ."""
    n = min(len(p1), len(p2))
    if n < window: return 0.0
    r1 = np.diff(np.log(p1[-n:] + 1e-10))
    r2 = np.diff(np.log(p2[-n:] + 1e-10))
    if len(r1) < 10: return 0.0
    return float(np.corrcoef(r1[-window:], r2[-window:])[0, 1])


def calc_cointegration_pvalue(p1, p2):
    """P-value ĞºĞ¾Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ğ¸."""
    try:
        _, pval, _ = coint(p1, p2)
        return float(pval)
    except:
        return 1.0


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# POSITIONS FILE (JSON persistence)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
POSITIONS_FILE = "positions.json"

def load_positions():
    if os.path.exists(POSITIONS_FILE):
        with open(POSITIONS_FILE) as f:
            return json.load(f)
    return []

def save_positions(positions):
    with open(POSITIONS_FILE, 'w') as f:
        json.dump(positions, f, indent=2, default=str)


def add_position(coin1, coin2, direction, entry_z, entry_hr, 
                 entry_price1, entry_price2, timeframe, notes="",
                 max_hold_hours=72, pnl_stop_pct=-5.0):
    positions = load_positions()
    # v5.0: Adaptive stop_z â€” at least 2.0 Z-units beyond entry
    adaptive_stop = max(abs(entry_z) + 2.0, 4.0)
    pos = {
        'id': len(positions) + 1,
        'coin1': coin1, 'coin2': coin2,
        'direction': direction,
        'entry_z': entry_z,
        'entry_hr': entry_hr,
        'entry_price1': entry_price1,
        'entry_price2': entry_price2,
        'entry_time': now_msk().isoformat(),
        'timeframe': timeframe,
        'status': 'OPEN',
        'notes': notes,
        'exit_z_target': 0.5,
        'stop_z': adaptive_stop,
        'max_hold_hours': max_hold_hours,
        'pnl_stop_pct': pnl_stop_pct,
    }
    positions.append(pos)
    save_positions(positions)
    return pos


def close_position(pos_id, exit_price1, exit_price2, exit_z, reason):
    positions = load_positions()
    for p in positions:
        if p['id'] == pos_id and p['status'] == 'OPEN':
            p['status'] = 'CLOSED'
            p['exit_price1'] = exit_price1
            p['exit_price2'] = exit_price2
            p['exit_z'] = exit_z
            p['exit_time'] = now_msk().isoformat()
            p['exit_reason'] = reason
            # P&L
            r1 = (exit_price1 - p['entry_price1']) / p['entry_price1']
            r2 = (exit_price2 - p['entry_price2']) / p['entry_price2']
            hr = p['entry_hr']
            if p['direction'] == 'LONG':
                raw = r1 - hr * r2
            else:
                raw = -r1 + hr * r2
            p['pnl_pct'] = round(raw / (1 + abs(hr)) * 100, 3)
            break
    save_positions(positions)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DATA FETCHING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# v4.0: Exchange fallback chain (Binance/Bybit block cloud servers)
EXCHANGE_FALLBACK = ['okx', 'kucoin', 'bybit', 'binance']

def _get_exchange(exchange_name):
    """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ñ€Ğ°Ğ±Ğ¾Ñ‡ÑƒÑ Ğ±Ğ¸Ñ€Ğ¶Ñƒ Ñ fallback."""
    tried = set()
    chain = [exchange_name] + [e for e in EXCHANGE_FALLBACK if e != exchange_name]
    for exch in chain:
        if exch in tried: continue
        tried.add(exch)
        try:
            ex = getattr(ccxt, exch)({'enableRateLimit': True})
            ex.load_markets()
            return ex, exch
        except:
            continue
    return None, None


@st.cache_data(ttl=120)
def fetch_prices(exchange_name, coin, timeframe, lookback_bars=300):
    try:
        ex, actual = _get_exchange(exchange_name)
        if ex is None: return None
        symbol = f"{coin}/USDT"
        ohlcv = ex.fetch_ohlcv(symbol, timeframe, limit=lookback_bars)
        df = pd.DataFrame(ohlcv, columns=['ts', 'o', 'h', 'l', 'c', 'v'])
        df['ts'] = pd.to_datetime(df['ts'], unit='ms')
        return df
    except:
        return None


def get_current_price(exchange_name, coin):
    try:
        ex, actual = _get_exchange(exchange_name)
        if ex is None: return None
        ticker = ex.fetch_ticker(f"{coin}/USDT")
        return ticker['last']
    except:
        return None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MONITOR LOGIC
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def monitor_position(pos, exchange_name):
    """ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ v3.0 â€” Ñ quality metrics."""
    c1, c2 = pos['coin1'], pos['coin2']
    tf = pos['timeframe']
    
    bars_map = {'1h': 300, '4h': 300, '1d': 120}
    n_bars = bars_map.get(tf, 300)
    
    df1 = fetch_prices(exchange_name, c1, tf, n_bars)
    df2 = fetch_prices(exchange_name, c2, tf, n_bars)
    
    if df1 is None or df2 is None:
        return None
    
    # Align timestamps
    merged = pd.merge(df1[['ts', 'c']], df2[['ts', 'c']], on='ts', suffixes=('_1', '_2'))
    if len(merged) < 50:
        return None
    
    p1 = merged['c_1'].values
    p2 = merged['c_2'].values
    ts = merged['ts'].tolist()
    
    # Kalman
    kf = kalman_hr(p1, p2)
    if kf is None:
        return None
    
    spread = kf['spread']
    hr_current = kf['hr']
    
    # v3.0: OU Half-life (dt-correct, ĞºĞ°Ğº Ğ² ÑĞºĞ°Ğ½ĞµÑ€Ğµ)
    dt_ou = {'1h': 1/24, '4h': 1/6, '1d': 1.0}.get(tf, 1/6)
    hpb = {'1h': 1, '4h': 4, '1d': 24}.get(tf, 4)
    
    # v18: Use SAME halflife function as scanner (critical for Z-window sync)
    if _USE_MRA:
        hl_days = calc_halflife_from_spread(spread, dt=dt_ou)
    else:
        hl_days = calc_halflife(spread, dt=dt_ou)
    hl_hours = hl_days * 24 if hl_days < 999 else 999
    hl_bars = (hl_hours / hpb) if hl_hours < 999 else None
    
    # v15: Use SAME Z-score function as scanner for consistency
    if _USE_MRA:
        z_now, zs, zw = calculate_adaptive_robust_zscore(spread, halflife_bars=hl_bars)
        # v18: GARCH Z for false convergence detection
        garch_info = calculate_garch_zscore(spread, halflife_bars=hl_bars)
        z_garch = garch_info.get('z_garch', z_now)
        garch_vol_ratio = garch_info.get('vol_ratio', 1.0)
        garch_var_expanding = garch_info.get('variance_expanding', False)
    else:
        zs, zw = calc_zscore(spread, halflife_bars=hl_bars)
        z_now = float(zs[~np.isnan(zs)][-1]) if any(~np.isnan(zs)) else 0
        z_garch = z_now
        garch_vol_ratio = 1.0
        garch_var_expanding = False
    
    # v3.0: Quality metrics (ĞºĞ°Ğº Ğ² ÑĞºĞ°Ğ½ĞµÑ€Ğµ)
    # v14: CRITICAL FIX â€” use SAME Hurst as scanner (DFA on increments)
    # v16: Hurst EMA smoothing
    if _USE_MRA:
        hurst_ema_info = calculate_hurst_ema(spread)
        hurst = hurst_ema_info.get('hurst_ema', 0.5)  # Use EMA, not raw
        hurst_raw = hurst_ema_info.get('hurst_raw', hurst)
        hurst_std = hurst_ema_info.get('hurst_std', 0)
    else:
        hurst = calc_hurst(spread)  # fallback
        hurst_raw = hurst
        hurst_std = 0
    corr = calc_correlation(p1, p2, window=min(60, len(p1) // 3))
    pvalue = calc_cointegration_pvalue(p1, p2)
    
    # v3.0: Entry readiness data
    quality_data = {
        'signal': 'SIGNAL' if abs(z_now) >= 2.0 else ('READY' if abs(z_now) >= 1.5 else 'NEUTRAL'),
        'zscore': z_now,
        'threshold': 2.0,
        'quality_score': max(0, int(100 - pvalue * 200 - max(0, hurst - 0.35) * 200)),
        'direction': pos['direction'],
        'fdr_passed': pvalue < 0.01,
        'confidence': 'HIGH' if (hurst < 0.4 and pvalue < 0.03) else ('MEDIUM' if pvalue < 0.05 else 'LOW'),
        'signal_score': max(0, int(abs(z_now) / 2.0 * 50 + (0.5 - hurst) * 100)),
        'correlation': corr,
        'stability_passed': 3 if pvalue < 0.05 else 1,
        'stability_total': 4,
        'hurst': hurst,
        'adf_passed': pvalue < 0.05,
    }
    
    # P&L (v4.0: price-based + spread-based + disagreement warning)
    r1 = (p1[-1] - pos['entry_price1']) / pos['entry_price1']
    r2 = (p2[-1] - pos['entry_price2']) / pos['entry_price2']
    hr = pos['entry_hr']
    if pos['direction'] == 'LONG':
        raw_pnl = r1 - hr * r2
    else:
        raw_pnl = -r1 + hr * r2
    pnl_pct = raw_pnl / (1 + abs(hr)) * 100
    
    # v4.0: Spread-based P&L (Ñ„Ğ¸ĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ HR Ğ¾Ñ‚ Ğ²Ñ…Ğ¾Ğ´Ğ°)
    entry_spread_val = pos['entry_price1'] - hr * pos['entry_price2']
    current_spread_val = p1[-1] - hr * p2[-1]
    spread_change = current_spread_val - entry_spread_val
    if pos['direction'] == 'LONG':
        spread_direction = 'profit' if spread_change > 0 else 'loss'
    else:
        spread_direction = 'profit' if spread_change < 0 else 'loss'
    
    # v4.0: Z-direction check
    z_entry = pos['entry_z']
    z_towards_zero = abs(z_now) < abs(z_entry)  # Z Ğ´Ğ²Ğ¸Ğ³Ğ°ĞµÑ‚ÑÑ Ğº 0 = Ğ² Ğ½Ğ°ÑˆÑƒ Ğ¿Ğ¾Ğ»ÑŒĞ·Ñƒ
    
    # v4.0: ĞŸÑ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¸ Ñ€Ğ°ÑÑ…Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ğ¸ P&L Ğ¸ Z-Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ
    # v14: Enhanced with variance collapse detection (Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğµ #1)
    pnl_z_disagree = False
    pnl_z_warning = ""
    
    # Use shared function if available
    if _USE_MRA:
        disagree_info = check_pnl_z_disagreement(z_entry, z_now, pnl_pct, pos['direction'])
        if disagree_info.get('disagreement'):
            pnl_z_disagree = True
            pnl_z_warning = disagree_info.get('warning', '')
    
    # Legacy checks (still useful as fallback)
    if not pnl_z_disagree:
        if pnl_pct > 0 and not z_towards_zero:
            pnl_z_disagree = True
            pnl_z_warning = (
                f"âš ï¸ P&L Ğ¿Ğ¾Ğ»Ğ¾Ğ¶Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ (+{pnl_pct:.2f}%), Ğ½Ğ¾ Z ÑƒÑˆÑ‘Ğ» Ğ´Ğ°Ğ»ÑŒÑˆĞµ Ğ¾Ñ‚ Ğ½ÑƒĞ»Ñ "
                f"({z_entry:+.2f} â†’ {z_now:+.2f}). "
                f"HR Ğ¸Ğ·Ğ¼ĞµĞ½Ğ¸Ğ»ÑÑ ({pos['entry_hr']:.4f} â†’ {hr_current:.4f})."
            )
        elif pnl_pct < -0.5 and z_towards_zero:
            pnl_z_disagree = True
            pnl_z_warning = (
                f"âš ï¸ Z â†’ 0 ({z_entry:+.2f} â†’ {z_now:+.2f}), Ğ½Ğ¾ P&L={pnl_pct:+.2f}%. "
                f"Ğ’Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ»Ğ¾Ğ¶Ğ½Ğ¾Ğµ ÑÑ…Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ğµ (Ïƒ ÑĞ¿Ñ€ĞµĞ´Ğ° Ğ²Ñ‹Ñ€Ğ¾ÑĞ»Ğ°)."
            )
    
    # Time in trade (Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ Ğ”Ğ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ)
    entry_dt = datetime.fromisoformat(pos['entry_time'])
    if entry_dt.tzinfo is None:
        entry_dt = entry_dt.replace(tzinfo=MSK)  # assume MSK if no tz
    hours_in = (now_msk() - entry_dt).total_seconds() / 3600
    
    # Exit signals
    exit_signal = None
    exit_urgency = 0
    ez = pos.get('exit_z_target', 0.5)
    # v5.0: Adaptive stop â€” at least 2.0 Z-units beyond entry, minimum 4.0
    default_stop = max(abs(pos['entry_z']) + 2.0, 4.0)
    sz = pos.get('stop_z', default_stop)
    max_hours = pos.get('max_hold_hours', 72)
    pnl_stop = pos.get('pnl_stop_pct', -5.0)
    
    if pos['direction'] == 'LONG':
        if z_now >= -ez and z_now <= ez:
            # v16: Check PnL before declaring convergence (Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğµ #1)
            # v18: Also check GARCH Z â€” if GARCH still far, it's variance collapse
            garch_still_far = abs(z_garch) > 1.5
            if pnl_pct > -0.3 and not garch_still_far:
                exit_signal = 'âœ… MEAN REVERT â€” Ğ·Ğ°ĞºÑ€Ñ‹Ğ²Ğ°Ñ‚ÑŒ!'
                exit_urgency = 2
            elif garch_still_far:
                exit_signal = (f'âš ï¸ Ğ›ĞĞ–ĞĞĞ• Ğ¡Ğ¥ĞĞ–Ğ”Ğ•ĞĞ˜Ğ•: Z_stdâ†’0 Ğ½Ğ¾ Z_GARCH={z_garch:+.1f}. '
                               f'Ïƒ Ğ²Ñ‹Ñ€Ğ¾ÑĞ»Ğ° Ğ² {garch_vol_ratio:.1f}x. Ğ ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ğ° Ğ½ĞµÑ‚.')
                exit_urgency = 1
            else:
                exit_signal = (f'âš ï¸ Ğ›ĞĞ–ĞĞĞ• Ğ¡Ğ¥ĞĞ–Ğ”Ğ•ĞĞ˜Ğ•: Zâ†’0 Ğ½Ğ¾ P&L={pnl_pct:+.2f}%. '
                               f'Ïƒ ÑĞ¿Ñ€ĞµĞ´Ğ° Ğ²Ñ‹Ñ€Ğ¾ÑĞ»Ğ°. Ğ–Ğ´Ğ¸Ñ‚Ğµ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ğ° Ñ†ĞµĞ½.')
                exit_urgency = 1
        elif z_now > 1.0:
            exit_signal = 'âœ… OVERSHOOT â€” Ñ„Ğ¸ĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ±Ñ‹Ğ»ÑŒ!'
            exit_urgency = 2
        elif z_now < -sz:
            exit_signal = 'ğŸ›‘ STOP LOSS (Z) â€” ÑĞºÑÑ‚Ñ€ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ñ…Ğ¾Ğ´!'
            exit_urgency = 2
    else:
        if z_now <= ez and z_now >= -ez:
            garch_still_far = abs(z_garch) > 1.5
            if pnl_pct > -0.3 and not garch_still_far:
                exit_signal = 'âœ… MEAN REVERT â€” Ğ·Ğ°ĞºÑ€Ñ‹Ğ²Ğ°Ñ‚ÑŒ!'
                exit_urgency = 2
            elif garch_still_far:
                exit_signal = (f'âš ï¸ Ğ›ĞĞ–ĞĞĞ• Ğ¡Ğ¥ĞĞ–Ğ”Ğ•ĞĞ˜Ğ•: Z_stdâ†’0 Ğ½Ğ¾ Z_GARCH={z_garch:+.1f}. '
                               f'Ïƒ Ğ²Ñ‹Ñ€Ğ¾ÑĞ»Ğ° Ğ² {garch_vol_ratio:.1f}x. Ğ ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ğ° Ğ½ĞµÑ‚.')
                exit_urgency = 1
            else:
                exit_signal = (f'âš ï¸ Ğ›ĞĞ–ĞĞĞ• Ğ¡Ğ¥ĞĞ–Ğ”Ğ•ĞĞ˜Ğ•: Zâ†’0 Ğ½Ğ¾ P&L={pnl_pct:+.2f}%. '
                               f'Ïƒ ÑĞ¿Ñ€ĞµĞ´Ğ° Ğ²Ñ‹Ñ€Ğ¾ÑĞ»Ğ°. Ğ–Ğ´Ğ¸Ñ‚Ğµ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ğ° Ñ†ĞµĞ½.')
                exit_urgency = 1
        elif z_now < -1.0:
            exit_signal = 'âœ… OVERSHOOT â€” Ñ„Ğ¸ĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ±Ñ‹Ğ»ÑŒ!'
            exit_urgency = 2
        elif z_now > sz:
            exit_signal = 'ğŸ›‘ STOP LOSS (Z) â€” ÑĞºÑÑ‚Ñ€ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ñ…Ğ¾Ğ´!'
            exit_urgency = 2
    
    # P&L stop
    if pnl_pct <= pnl_stop and exit_urgency < 2:
        exit_signal = f'ğŸ›‘ STOP LOSS (P&L {pnl_pct:.1f}% < {pnl_stop:.0f}%) â€” Ğ²Ñ‹Ñ…Ğ¾Ğ´!'
        exit_urgency = 2
    
    # Time-based
    if hours_in > max_hours and exit_urgency < 2:
        if exit_signal is None:
            exit_signal = f'â° TIMEOUT ({hours_in:.0f}Ñ‡ > {max_hours:.0f}Ñ‡) â€” Ñ€Ğ°ÑÑĞ¼Ğ¾Ñ‚Ñ€Ğ¸Ñ‚Ğµ Ğ²Ñ‹Ñ…Ğ¾Ğ´'
            exit_urgency = 1
    elif hours_in > max_hours * 0.75 and exit_urgency == 0:
        exit_signal = f'âš ï¸ ĞŸĞ¾Ğ·Ğ¸Ñ†Ğ¸Ñ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ğ° {hours_in:.0f}Ñ‡ (Ğ»Ğ¸Ğ¼Ğ¸Ñ‚ {max_hours:.0f}Ñ‡)'
        exit_urgency = 1
    
    # v5.3: Quality warnings (v16: uses EMA Hurst)
    quality_warnings = []
    if hurst >= 0.50:
        quality_warnings.append(
            f"ğŸš¨ Hurst(EMA)={hurst:.3f} â‰¥ 0.50 â€” Ğ½ĞµÑ‚ mean reversion!"
            + (f" (raw={hurst_raw:.3f}, Ïƒ={hurst_std:.3f})" if hurst_std > 0 else ""))
    elif hurst >= 0.48:
        quality_warnings.append(f"âš ï¸ Hurst(EMA)={hurst:.3f} â‰¥ 0.48 â€” Ğ¾ÑĞ»Ğ°Ğ±ĞµĞ²Ğ°ĞµÑ‚")
    elif hurst >= 0.45:
        quality_warnings.append(f"ğŸ’¡ Hurst(EMA)={hurst:.3f} â€” Ğ¿Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ½Ğ¾Ğµ")
    if pvalue >= 0.10:
        quality_warnings.append(f"âš ï¸ P-value={pvalue:.3f} â€” ĞºĞ¾Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¾ÑĞ»Ğ°Ğ±Ğ»Ğ°!")
    if corr < 0.2:
        quality_warnings.append(f"âš ï¸ ĞšĞ¾Ñ€Ñ€ĞµĞ»ÑÑ†Ğ¸Ñ Ï={corr:.2f} < 0.2 â€” Ñ…ĞµĞ´Ğ¶ Ğ½Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚!")
    
    # v18: Direction sanity check â€” warn if direction contradicts entry Z
    entry_z = pos.get('entry_z', 0)
    direction = pos.get('direction', '')
    if entry_z < -0.5 and direction == 'SHORT':
        quality_warnings.append(
            f"ğŸš¨ ĞĞĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ˜Ğ• Ğ˜ĞĞ’Ğ•Ğ Ğ¢Ğ˜Ğ ĞĞ’ĞĞĞ: Entry_Z={entry_z:+.2f} (Ğ¾Ñ‚Ñ€Ğ¸Ñ†Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹) "
            f"Ğ½Ğ¾ Dir=SHORT. Ğ”Ğ»Ñ Z<0 Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ LONG! ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ Ğ²Ğ²Ğ¾Ğ´.")
    elif entry_z > 0.5 and direction == 'LONG':
        quality_warnings.append(
            f"ğŸš¨ ĞĞĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ˜Ğ• Ğ˜ĞĞ’Ğ•Ğ Ğ¢Ğ˜Ğ ĞĞ’ĞĞĞ: Entry_Z={entry_z:+.2f} (Ğ¿Ğ¾Ğ»Ğ¾Ğ¶Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹) "
            f"Ğ½Ğ¾ Dir=LONG. Ğ”Ğ»Ñ Z>0 Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ SHORT! ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ Ğ²Ğ²Ğ¾Ğ´.")
    
    return {
        'z_now': z_now,
        'z_entry': pos['entry_z'],
        'pnl_pct': pnl_pct,
        'spread_direction': spread_direction,
        'z_towards_zero': z_towards_zero,
        'pnl_z_disagree': pnl_z_disagree,
        'pnl_z_warning': pnl_z_warning,
        'price1_now': p1[-1],
        'price2_now': p2[-1],
        'hr_now': hr_current,
        'hr_entry': pos['entry_hr'],
        'exit_signal': exit_signal,
        'exit_urgency': exit_urgency,
        'hours_in': hours_in,
        'spread': spread,
        'zscore_series': zs,
        'timestamps': ts,
        'hr_series': kf['hrs'],
        'halflife_hours': hl_hours,
        'z_window': zw,
        # v3.0: quality metrics
        'hurst': hurst,
        'correlation': corr,
        'pvalue': pvalue,
        'quality_data': quality_data,
        'quality_warnings': quality_warnings,
        # v18: GARCH Z
        'z_garch': z_garch,
        'garch_vol_ratio': garch_vol_ratio,
        'garch_var_expanding': garch_var_expanding,
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STREAMLIT UI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

st.set_page_config(page_title="Position Monitor", page_icon="ğŸ“", layout="wide")

st.markdown("""
<style>
    .exit-signal { padding: 15px; border-radius: 10px; font-size: 1.2em; 
                   font-weight: bold; text-align: center; margin: 10px 0; }
    .signal-exit { background: #1b5e20; color: #a5d6a7; }
    .signal-stop { background: #b71c1c; color: #ef9a9a; }
</style>
""", unsafe_allow_html=True)

st.title("ğŸ“ Pairs Position Monitor")
st.caption("v14.0 | 23.02.2026 | Portfolio Risk v2 + HR Drift Monitor + Direction check")

# Sidebar
with st.sidebar:
    st.header("âš™ï¸ ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸")
    exchange = st.selectbox("Ğ‘Ğ¸Ñ€Ğ¶Ğ°", ['okx', 'kucoin', 'bybit', 'binance'], index=0,
                           help="âš ï¸ Binance/Bybit Ğ·Ğ°Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹ Ğ½Ğ° Ğ¾Ğ±Ğ»Ğ°Ñ‡Ğ½Ñ‹Ñ… ÑĞµÑ€Ğ²ĞµÑ€Ğ°Ñ…. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ OKX/KuCoin.")
    auto_refresh = st.checkbox("ĞĞ²Ñ‚Ğ¾-Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ (2 Ğ¼Ğ¸Ğ½)", value=False)
    
    st.divider()
    st.header("â• ĞĞ¾Ğ²Ğ°Ñ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ")
    
    with st.form("add_position"):
        col1, col2 = st.columns(2)
        with col1:
            new_c1 = st.text_input("Coin 1", "ETH").upper().strip()
        with col2:
            new_c2 = st.text_input("Coin 2", "STETH").upper().strip()
        
        new_dir = st.selectbox("ĞĞ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ", ["LONG", "SHORT"])
        new_tf = st.selectbox("Ğ¢Ğ°Ğ¹Ğ¼Ñ„Ñ€ĞµĞ¹Ğ¼", ['1h', '4h', '1d'], index=1)
        
        col3, col4 = st.columns(2)
        with col3:
            new_z = st.number_input("Entry Z", value=2.0, step=0.1)
        with col4:
            new_hr = st.number_input("Hedge Ratio", value=1.0, step=0.01, format="%.4f")
        
        col5, col6 = st.columns(2)
        with col5:
            new_p1 = st.number_input("Ğ¦ĞµĞ½Ğ° Coin1", value=0.0, step=0.01, format="%.4f")
        with col6:
            new_p2 = st.number_input("Ğ¦ĞµĞ½Ğ° Coin2", value=0.0, step=0.01, format="%.4f")
        
        new_notes = st.text_input("Ğ—Ğ°Ğ¼ĞµÑ‚ĞºĞ¸", "")
        
        # v2.0: Risk management
        st.markdown("**âš ï¸ Ğ Ğ¸ÑĞº-Ğ¼ĞµĞ½ĞµĞ´Ğ¶Ğ¼ĞµĞ½Ñ‚**")
        col_r1, col_r2 = st.columns(2)
        with col_r1:
            new_max_hours = st.number_input("Max Ñ‡Ğ°ÑĞ¾Ğ² Ğ² Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸", value=72, step=12)
        with col_r2:
            new_pnl_stop = st.number_input("P&L Stop (%)", value=-5.0, step=0.5)
        
        # ĞĞ²Ñ‚Ğ¾Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ñ†ĞµĞ½
        fetch_prices_btn = st.form_submit_button("ğŸ“¥ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ñ†ĞµĞ½Ñ‹ + Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ")
    
    if fetch_prices_btn and new_c1 and new_c2:
        if new_p1 == 0 or new_p2 == 0:
            with st.spinner("Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°Ñ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğµ Ñ†ĞµĞ½Ñ‹..."):
                p1_live = get_current_price(exchange, new_c1)
                p2_live = get_current_price(exchange, new_c2)
                if p1_live and p2_live:
                    new_p1 = p1_live
                    new_p2 = p2_live
                    st.info(f"ğŸ’° {new_c1}: ${p1_live:.4f} | {new_c2}: ${p2_live:.4f}")
                else:
                    st.error("ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ñ†ĞµĞ½Ñ‹")
        
        if new_p1 > 0 and new_p2 > 0:
            pos = add_position(new_c1, new_c2, new_dir, new_z, new_hr,
                             new_p1, new_p2, new_tf, new_notes,
                             max_hold_hours=new_max_hours,
                             pnl_stop_pct=new_pnl_stop)
            st.success(f"âœ… ĞŸĞ¾Ğ·Ğ¸Ñ†Ğ¸Ñ #{pos['id']} Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ°: {new_dir} {new_c1}/{new_c2}")
            st.rerun()

# â•â•â•â•â•â•â• MAIN AREA â•â•â•â•â•â•â•
positions = load_positions()
open_positions = [p for p in positions if p['status'] == 'OPEN']
closed_positions = [p for p in positions if p['status'] == 'CLOSED']

# Tabs
tab1, tab2, tab3 = st.tabs([f"ğŸ“ ĞÑ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ğµ ({len(open_positions)})", 
                       f"ğŸ“‹ Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ ({len(closed_positions)})",
                       f"ğŸ“Š ĞŸĞ¾Ñ€Ñ‚Ñ„ĞµĞ»ÑŒ"])

with tab1:
    if not open_positions:
        st.info("ğŸ“­ ĞĞµÑ‚ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ñ… Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¹. Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒÑ‚Ğµ Ñ‡ĞµÑ€ĞµĞ· Ğ±Ğ¾ĞºĞ¾Ğ²ÑƒÑ Ğ¿Ğ°Ğ½ĞµĞ»ÑŒ.")
    else:
        # Dashboard metrics
        total_pnl = 0
        
        for pos in open_positions:
            with st.container():
                st.markdown("---")
                
                # Header
                dir_emoji = 'ğŸŸ¢' if pos['direction'] == 'LONG' else 'ğŸ”´'
                pair_name = f"{pos['coin1']}/{pos['coin2']}"
                
                # Monitor
                with st.spinner(f"ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑÑ {pair_name}..."):
                    mon = monitor_position(pos, exchange)
                
                if mon is None:
                    st.error(f"âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ {pair_name}")
                    continue
                
                total_pnl += mon['pnl_pct']
                
                # Exit signal banner
                if mon['exit_signal']:
                    if 'STOP' in mon['exit_signal']:
                        st.error(mon['exit_signal'])
                    else:
                        st.success(mon['exit_signal'])
                
                # Header row
                dir_emoji_c1 = 'ğŸŸ¢ LONG' if pos['direction'] == 'LONG' else 'ğŸ”´ SHORT'
                dir_emoji_c2 = 'ğŸ”´ SHORT' if pos['direction'] == 'LONG' else 'ğŸŸ¢ LONG'
                st.subheader(f"{dir_emoji} {pos['direction']} | {pair_name} | #{pos['id']}")
                st.caption(f"{pos['coin1']}: {dir_emoji_c1} | {pos['coin2']}: {dir_emoji_c2}")
                
                # v4.0: P&L / Z disagreement warning
                if mon.get('pnl_z_disagree'):
                    st.warning(mon['pnl_z_warning'])
                
                # KPI row
                c1, c2, c3, c4, c5, c6 = st.columns(6)
                
                pnl_color = "normal" if mon['pnl_pct'] > 0 else "inverse"
                c1.metric("P&L", f"{mon['pnl_pct']:+.2f}%", 
                         delta="profit" if mon['pnl_pct'] > 0 else "loss")
                c2.metric("Z ÑĞµĞ¹Ñ‡Ğ°Ñ", f"{mon['z_now']:+.2f}",
                         delta=f"Ğ²Ñ…Ğ¾Ğ´: {mon['z_entry']:+.2f}")
                c3.metric("HR", f"{mon['hr_now']:.4f}",
                         delta=f"Ğ²Ñ…Ğ¾Ğ´: {mon['hr_entry']:.4f}")
                c4.metric(f"{pos['coin1']} {'ğŸŸ¢' if pos['direction']=='LONG' else 'ğŸ”´'}", 
                         f"${mon['price1_now']:.4f}",
                         delta=f"Ğ²Ñ…Ğ¾Ğ´: ${pos['entry_price1']:.4f}")
                c5.metric(f"{pos['coin2']} {'ğŸ”´' if pos['direction']=='LONG' else 'ğŸŸ¢'}", 
                         f"${mon['price2_now']:.4f}",
                         delta=f"Ğ²Ñ…Ğ¾Ğ´: ${pos['entry_price2']:.4f}")
                c6.metric("Ğ’ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸", f"{mon['hours_in']:.0f}Ñ‡",
                         delta=f"HL: {mon['halflife_hours']:.0f}Ñ‡")
                
                # v3.0: Quality metrics row
                q1, q2, q3, q4 = st.columns(4)
                q1.metric("Hurst", f"{mon.get('hurst', 0.5):.3f}",
                         delta="ğŸŸ¢ MR" if mon.get('hurst', 0.5) < 0.45 else "ğŸ”´ No MR")
                q2.metric("P-value", f"{mon.get('pvalue', 1.0):.4f}",
                         delta="âœ… Coint" if mon.get('pvalue', 1.0) < 0.05 else "âš ï¸ Weak")
                q3.metric("ĞšĞ¾Ñ€Ñ€ĞµĞ»ÑÑ†Ğ¸Ñ Ï", f"{mon.get('correlation', 0):.3f}",
                         delta="ğŸŸ¢" if mon.get('correlation', 0) >= 0.5 else "âš ï¸")
                q4.metric("Z-window", f"{mon.get('z_window', 30)} Ğ±Ğ°Ñ€Ğ¾Ğ²")
                
                # v18: GARCH Z row
                if mon.get('z_garch') is not None:
                    gq1, gq2, gq3, gq4 = st.columns(4)
                    gq1.metric("Z GARCH", f"{mon.get('z_garch', 0):+.2f}",
                               f"vs std={mon.get('z_now',0):+.2f}")
                    vr = mon.get('garch_vol_ratio', 1.0)
                    gq2.metric("Ïƒ ratio", f"{vr:.2f}x",
                               "ğŸ”´ Ñ€Ğ°ÑÑ‚Ñ‘Ñ‚" if mon.get('garch_var_expanding') else "âœ… ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ°")
                    gq3.metric("HL Ñ‡Ğ°ÑĞ¾Ğ²", f"{mon.get('halflife_hours', 0):.1f}")
                    gq4.metric("Z-window", f"{mon.get('z_window', 30)} Ğ±Ğ°Ñ€")
                
                # v20: Dynamic HR Drift Monitoring (P4 Roadmap)
                hr_entry = pos.get('entry_hr', 0)
                hr_now = mon.get('hr_now', hr_entry)
                if hr_entry > 0 and hr_now > 0:
                    hr_drift_pct = abs(hr_now - hr_entry) / hr_entry * 100
                    
                    if hr_drift_pct > 5:  # Only show if drift is significant
                        st.markdown("#### ğŸ“ HR Drift Monitor")
                        hd1, hd2, hd3 = st.columns(3)
                        with hd1:
                            dr_emoji = 'âœ…' if hr_drift_pct < 10 else 'ğŸŸ¡' if hr_drift_pct < 20 else 'ğŸ”´'
                            st.metric("HR Ğ´Ñ€ĞµĞ¹Ñ„", f"{dr_emoji} {hr_drift_pct:.1f}%",
                                     f"Entry: {hr_entry:.4f} â†’ Now: {hr_now:.4f}")
                        with hd2:
                            # Calculate impact: how much spread changed due to HR drift alone
                            p2_now = mon.get('price2_now', pos.get('entry_price2', 1))
                            hr_impact = abs(hr_now - hr_entry) * p2_now
                            st.metric("Ğ’Ğ»Ğ¸ÑĞ½Ğ¸Ğµ Ğ½Ğ° ÑĞ¿Ñ€ĞµĞ´", f"{hr_impact:.4f}",
                                     "USD ÑĞ´Ğ²Ğ¸Ğ³ Ğ¾Ñ‚ Ğ´Ñ€ĞµĞ¹Ñ„Ğ° HR")
                        with hd3:
                            # Rebalance suggestion
                            if hr_drift_pct > 15:
                                st.metric("Ğ ĞµĞ±Ğ°Ğ»Ğ°Ğ½Ñ", "ğŸ”´ ĞĞ£Ğ–Ğ•Ğ",
                                         f"HR Ğ¸Ğ·Ğ¼ĞµĞ½Ğ¸Ğ»ÑÑ Ğ½Ğ° {hr_drift_pct:.0f}%")
                            elif hr_drift_pct > 10:
                                st.metric("Ğ ĞµĞ±Ğ°Ğ»Ğ°Ğ½Ñ", "ğŸŸ¡ Ğ Ğ°ÑÑĞ¼Ğ¾Ñ‚Ñ€Ğ¸Ñ‚Ğµ",
                                         f"HR Ğ´Ñ€ĞµĞ¹Ñ„ÑƒĞµÑ‚")
                            else:
                                st.metric("Ğ ĞµĞ±Ğ°Ğ»Ğ°Ğ½Ñ", "âœ… ĞĞµ Ğ½ÑƒĞ¶ĞµĞ½", "Ğ”Ñ€ĞµĞ¹Ñ„ Ğ² Ğ½Ğ¾Ñ€Ğ¼Ğµ")
                        
                        if hr_drift_pct > 20:
                            st.error(
                                f"ğŸš¨ **HR Ğ”Ğ Ğ•Ğ™Ğ¤ ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ™: {hr_drift_pct:.1f}%**. "
                                f"Entry HR={hr_entry:.4f}, Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğ¹={hr_now:.4f}. "
                                f"ĞšĞ¾Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¼Ğ¾Ğ³Ğ»Ğ° Ñ€Ğ°Ğ·Ñ€ÑƒÑˆĞ¸Ñ‚ÑŒÑÑ. Ğ Ğ°ÑÑĞ¼Ğ¾Ñ‚Ñ€Ğ¸Ñ‚Ğµ Ğ·Ğ°ĞºÑ€Ñ‹Ñ‚Ğ¸Ğµ.")
                        elif hr_drift_pct > 15:
                            st.warning(
                                f"âš ï¸ **HR Ğ´Ñ€ĞµĞ¹Ñ„ {hr_drift_pct:.1f}%**: Entry={hr_entry:.4f}, "
                                f"Now={hr_now:.4f}. Ğ ĞµĞ±Ğ°Ğ»Ğ°Ğ½ÑĞ¸Ñ€ÑƒĞ¹Ñ‚Ğµ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ Ğ¸Ğ»Ğ¸ Ğ·Ğ°ĞºÑ€Ğ¾Ğ¹Ñ‚Ğµ.")
                
                # v3.0: Quality warnings
                for qw in mon.get('quality_warnings', []):
                    st.warning(qw)
                
                # v3.0: Entry readiness assessment
                qd = mon.get('quality_data', {})
                if qd:
                    ea = assess_entry_readiness(qd)
                    with st.expander("ğŸ“‹ ĞšÑ€Ğ¸Ñ‚ĞµÑ€Ğ¸Ğ¸ Ğ²Ñ…Ğ¾Ğ´Ğ° (ĞºĞ°Ğº Ğ² ÑĞºĞ°Ğ½ĞµÑ€Ğµ)", expanded=False):
                        ec1, ec2 = st.columns(2)
                        with ec1:
                            st.markdown("**ğŸŸ¢ ĞĞ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ:**")
                            for name, met, val in ea['mandatory']:
                                st.markdown(f"  {'âœ…' if met else 'âŒ'} **{name}** â†’ `{val}`")
                        with ec2:
                            st.markdown("**ğŸ”µ Ğ–ĞµĞ»Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ:**")
                            for name, met, val in ea['optional']:
                                st.markdown(f"  {'âœ…' if met else 'â¬œ'} {name} â†’ `{val}`")
                
                # Chart
                with st.expander("ğŸ“ˆ Ğ“Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸", expanded=False):
                    fig = make_subplots(rows=2, cols=1, shared_xaxes=True,
                                       vertical_spacing=0.08,
                                       subplot_titles=['Z-Score', 'Ğ¡Ğ¿Ñ€ĞµĞ´'],
                                       row_heights=[0.6, 0.4])
                    
                    ts = mon['timestamps']
                    
                    # Z-score
                    fig.add_trace(go.Scatter(
                        x=ts, y=mon['zscore_series'],
                        name='Z-Score', line=dict(color='#4fc3f7', width=2)
                    ), row=1, col=1)
                    
                    fig.add_hline(y=0, line_dash='dash', line_color='gray', 
                                 opacity=0.5, row=1, col=1)
                    fig.add_hline(y=pos.get('exit_z_target', 0.5), 
                                 line_dash='dot', line_color='#4caf50',
                                 opacity=0.5, row=1, col=1)
                    fig.add_hline(y=-pos.get('exit_z_target', 0.5), 
                                 line_dash='dot', line_color='#4caf50',
                                 opacity=0.5, row=1, col=1)
                    
                    # Entry Z marker
                    entry_dt = datetime.fromisoformat(pos['entry_time'])
                    fig.add_trace(go.Scatter(
                        x=[entry_dt], y=[pos['entry_z']],
                        mode='markers', marker=dict(size=14, color='yellow',
                                                     symbol='star'),
                        name='Entry', showlegend=True
                    ), row=1, col=1)
                    
                    # Spread
                    fig.add_trace(go.Scatter(
                        x=ts, y=mon['spread'],
                        name='Spread', line=dict(color='#ffa726', width=1.5)
                    ), row=2, col=1)
                    
                    fig.update_layout(height=400, template='plotly_dark',
                                     showlegend=False,
                                     margin=dict(l=50, r=30, t=30, b=30))
                    st.plotly_chart(fig, use_container_width=True)
                
                # Close button
                col_close1, col_close2, col_close3 = st.columns([2, 2, 1])
                with col_close3:
                    if st.button(f"âŒ Ğ—Ğ°ĞºÑ€Ñ‹Ñ‚ÑŒ #{pos['id']}", key=f"close_{pos['id']}"):
                        close_position(
                            pos['id'], 
                            mon['price1_now'], mon['price2_now'],
                            mon['z_now'], 'MANUAL'
                        )
                        st.success(f"ĞŸĞ¾Ğ·Ğ¸Ñ†Ğ¸Ñ #{pos['id']} Ğ·Ğ°ĞºÑ€Ñ‹Ñ‚Ğ° | P&L: {mon['pnl_pct']:+.2f}%")
                        st.rerun()
        
        # Total P&L
        st.markdown("---")
        st.metric("ğŸ“Š Ğ¡ÑƒĞ¼Ğ¼Ğ°Ñ€Ğ½Ñ‹Ğ¹ P&L (Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ğµ)", f"{total_pnl:+.2f}%")
        
        # v5.2: FULL open positions CSV with live monitoring data
        open_rows = []
        for pos in open_positions:
            row = {
                '#': pos['id'],
                'ĞŸĞ°Ñ€Ğ°': f"{pos['coin1']}/{pos['coin2']}",
                'Dir': pos['direction'],
                'TF': pos['timeframe'],
                'Entry_Z': pos['entry_z'],
                'Entry_HR': pos.get('entry_hr', 0),
                'Stop_Z': pos.get('stop_z', 4.0),
                'Entry_Time': pos['entry_time'][:16],
                'Entry_Price1': pos.get('entry_price1', 0),
                'Entry_Price2': pos.get('entry_price2', 0),
            }
            # Add live data if available
            try:
                mon = monitor_position(pos, exchange)
                if mon:
                    row.update({
                        'Current_Z': round(mon['z_now'], 4),
                        'Current_HR': round(mon['hr_now'], 4),
                        'P&L_%': round(mon['pnl_pct'], 4),
                        'Hours_In': round(mon['hours_in'], 1),
                        'HL_hours': round(mon['halflife_hours'], 1),
                        'Price1_Now': round(mon['price1_now'], 6),
                        'Price2_Now': round(mon['price2_now'], 6),
                        'Hurst': round(mon.get('hurst', 0.5), 4),
                        'Correlation': round(mon.get('correlation', 0), 4),
                        'P-value': round(mon.get('pvalue', 1.0), 6),
                        'Z_Window': mon.get('z_window', 30),
                        'Exit_Signal': mon.get('exit_signal', ''),
                        'Exit_Urgency': mon.get('exit_urgency', ''),
                        'Z_Toward_Zero': mon.get('z_towards_zero', False),
                        'PnL_Z_Disagree': mon.get('pnl_z_disagree', False),
                        'Quality_Warnings': '; '.join(mon.get('quality_warnings', [])),
                    })
            except Exception:
                pass
            open_rows.append(row)
        
        if open_rows:
            csv_open = pd.DataFrame(open_rows).to_csv(index=False)
            st.download_button("ğŸ“¥ Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ğµ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ (CSV)", csv_open,
                f"positions_open_{now_msk().strftime('%Y%m%d_%H%M')}.csv", "text/csv",
                key="open_pos_csv")
            
            # v20.1: Auto-save positions to disk every 10 minutes
            try:
                import os
                os.makedirs("position_exports", exist_ok=True)
                last_auto_save = st.session_state.get('_last_pos_save', 0)
                now_ts = time.time()
                if now_ts - last_auto_save > 600:  # 10 minutes
                    save_path = f"position_exports/positions_open_{now_msk().strftime('%Y%m%d_%H%M')}.csv"
                    pd.DataFrame(open_rows).to_csv(save_path, index=False)
                    st.session_state['_last_pos_save'] = now_ts
                    st.toast(f"ğŸ’¾ ĞŸĞ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹: {save_path}")
            except Exception:
                pass

with tab2:
    if not closed_positions:
        st.info("ğŸ“­ ĞĞµÑ‚ Ğ·Ğ°ĞºÑ€Ñ‹Ñ‚Ñ‹Ñ… Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¹")
    else:
        # Summary
        pnls = [p.get('pnl_pct', 0) for p in closed_positions]
        wins = [p for p in pnls if p > 0]
        
        sc1, sc2, sc3, sc4 = st.columns(4)
        sc1.metric("Ğ¡Ğ´ĞµĞ»Ğ¾Ğº", len(closed_positions))
        sc2.metric("Win Rate", f"{len(wins)/len(closed_positions)*100:.0f}%" if closed_positions else "0%")
        sc3.metric("Total P&L", f"{sum(pnls):+.2f}%")
        sc4.metric("Avg P&L", f"{np.mean(pnls):+.2f}%" if pnls else "0%")
        
        # Table
        rows = []
        for p in reversed(closed_positions):
            rows.append({
                '#': p['id'],
                'ĞŸĞ°Ñ€Ğ°': f"{p['coin1']}/{p['coin2']}",
                'Dir': p['direction'],
                'TF': p['timeframe'],
                'Entry Z': f"{p['entry_z']:+.2f}",
                'Exit Z': f"{p.get('exit_z', 0):+.2f}",
                'P&L %': f"{p.get('pnl_pct', 0):+.2f}",
                'ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ°': p.get('exit_reason', ''),
                'Ğ’Ñ…Ğ¾Ğ´': p['entry_time'][:16],
                'Ğ’Ñ‹Ñ…Ğ¾Ğ´': p.get('exit_time', '')[:16] if p.get('exit_time') else '',
            })
        st.dataframe(pd.DataFrame(rows), use_container_width=True, hide_index=True)
        
        # v5.1: CSV export with date in filename
        csv_history = pd.DataFrame(rows).to_csv(index=False)
        # Date range from trades
        dates = [p.get('exit_time', '')[:10] for p in closed_positions if p.get('exit_time')]
        date_suffix = dates[-1] if dates else now_msk().strftime('%Y-%m-%d')
        st.download_button("ğŸ“¥ Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ ÑĞ´ĞµĞ»Ğ¾Ğº (CSV)", csv_history,
                          f"trades_history_{date_suffix}_{now_msk().strftime('%H%M')}.csv", "text/csv")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TAB 3: PORTFOLIO RISK MANAGER (v19.0)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with tab3:
    if not open_positions:
        st.info("ğŸ“­ ĞĞµÑ‚ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ñ… Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ¿Ğ¾Ñ€Ñ‚Ñ„ĞµĞ»Ñ.")
    else:
        st.markdown("### ğŸ“Š Portfolio Risk Manager v2.0")
        
        # === 1. Collect all monitoring data upfront ===
        mon_cache = {}
        for pos in open_positions:
            pair = f"{pos['coin1']}/{pos['coin2']}"
            try:
                mon = monitor_position(pos, exchange)
                if mon:
                    mon_cache[pos['id']] = mon
            except Exception:
                pass
        
        # === 2. Portfolio summary metrics ===
        total_pnl_port = sum(m['pnl_pct'] for m in mon_cache.values())
        n_pos = len(open_positions)
        n_profit = sum(1 for m in mon_cache.values() if m['pnl_pct'] > 0)
        n_loss = sum(1 for m in mon_cache.values() if m['pnl_pct'] < 0)
        
        pc1, pc2, pc3, pc4 = st.columns(4)
        pc1.metric("ĞŸĞ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¹", n_pos)
        pc2.metric("Ğ¡Ğ¾Ğ²Ğ¾ĞºÑƒĞ¿Ğ½Ñ‹Ğ¹ P&L", f"{total_pnl_port:+.3f}%")
        pc3.metric("ĞŸÑ€Ğ¸Ğ±Ñ‹Ğ»ÑŒĞ½Ñ‹Ñ…", f"{n_profit}/{n_pos}",
                  f"{n_profit/n_pos*100:.0f}%" if n_pos > 0 else "â€”")
        avg_hours = sum(pos.get('hours_in', 0) for pos in open_positions) / n_pos if n_pos > 0 else 0
        pc4.metric("Ğ¡Ñ€. Ğ²Ñ€ĞµĞ¼Ñ Ğ² Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸", f"{avg_hours:.1f}Ñ‡")
        
        # === 3. Coin exposure map ===
        st.markdown("#### ğŸª™ Ğ­ĞºÑĞ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ Ğ¿Ğ¾ Ğ¼Ğ¾Ğ½ĞµÑ‚Ğ°Ğ¼")
        coin_exposure = {}
        for pos in open_positions:
            c1, c2 = pos['coin1'], pos['coin2']
            d = pos['direction']
            for coin, coin_dir in [(c1, d), (c2, 'SHORT' if d == 'LONG' else 'LONG')]:
                if coin not in coin_exposure:
                    coin_exposure[coin] = {'long': 0, 'short': 0, 'pairs': [], 'pnl': 0.0}
                if coin_dir == 'LONG':
                    coin_exposure[coin]['long'] += 1
                else:
                    coin_exposure[coin]['short'] += 1
                coin_exposure[coin]['pairs'].append(f"{c1}/{c2}")
                mon = mon_cache.get(pos['id'])
                if mon:
                    coin_exposure[coin]['pnl'] += mon['pnl_pct'] / 2  # Split P&L between legs
        
        for coin, data in coin_exposure.items():
            data['net'] = data['long'] - data['short']
            data['total'] = data['long'] + data['short']
        
        sorted_coins = sorted(coin_exposure.items(), key=lambda x: x[1]['total'], reverse=True)
        
        # Concentration metric
        max_coin = sorted_coins[0] if sorted_coins else ('â€”', {'total': 0})
        max_exposure_pct = max_coin[1]['total'] / (n_pos * 2) * 100 if n_pos > 0 else 0
        
        # Exposure table
        coin_rows = []
        for coin, data in sorted_coins:
            conflict = 'ğŸš¨ ĞšĞĞĞ¤Ğ›Ğ˜ĞšĞ¢' if data['long'] > 0 and data['short'] > 0 else ''
            pct_of_port = data['total'] / (n_pos * 2) * 100 if n_pos > 0 else 0
            bar = 'â–ˆ' * int(pct_of_port / 5) + 'â–‘' * (20 - int(pct_of_port / 5))
            coin_rows.append({
                'ĞœĞ¾Ğ½ĞµÑ‚Ğ°': coin,
                'LONG': data['long'],
                'SHORT': data['short'],
                'Ğ’ÑĞµĞ³Ğ¾': data['total'],
                'Net': f"+{data['net']}" if data['net'] > 0 else str(data['net']),
                '% Ğ¿Ğ¾Ñ€Ñ‚.': f"{pct_of_port:.0f}%",
                'P&L': f"{data['pnl']:+.3f}%",
                'ĞšĞ¾Ğ½Ñ„Ğ»Ğ¸ĞºÑ‚': conflict,
                'ĞŸĞ°Ñ€Ñ‹': ', '.join(set(data['pairs'])),
            })
        if coin_rows:
            st.dataframe(pd.DataFrame(coin_rows), use_container_width=True, hide_index=True)
        
        # === 4. RISK LIMITS CHECK ===
        st.markdown("#### âš ï¸ Ğ›Ğ¸Ğ¼Ğ¸Ñ‚Ñ‹ Ñ€Ğ¸ÑĞºĞ°")
        
        MAX_POSITIONS = 6
        MAX_COIN_EXPOSURE = 3  # max positions per coin
        MAX_CONCENTRATION_PCT = 40  # max % of portfolio in one coin
        
        lc1, lc2, lc3 = st.columns(3)
        
        with lc1:
            pos_ok = n_pos <= MAX_POSITIONS
            st.metric(
                "ĞŸĞ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¹", f"{n_pos}/{MAX_POSITIONS}",
                "âœ… OK" if pos_ok else "ğŸ”´ ĞŸĞ Ğ•Ğ’Ğ«Ğ¨Ğ•Ğ",
                delta_color="normal" if pos_ok else "inverse"
            )
        
        with lc2:
            max_c = max_coin[1]['total'] if sorted_coins else 0
            coin_ok = max_c <= MAX_COIN_EXPOSURE
            st.metric(
                f"ĞœĞ°ĞºÑ Ğ½Ğ° Ğ¼Ğ¾Ğ½ĞµÑ‚Ñƒ ({max_coin[0]})", f"{max_c}/{MAX_COIN_EXPOSURE}",
                "âœ… OK" if coin_ok else "ğŸ”´ ĞŸĞ Ğ•Ğ’Ğ«Ğ¨Ğ•Ğ",
                delta_color="normal" if coin_ok else "inverse"
            )
        
        with lc3:
            conc_ok = max_exposure_pct <= MAX_CONCENTRATION_PCT
            st.metric(
                "ĞšĞ¾Ğ½Ñ†ĞµĞ½Ñ‚Ñ€Ğ°Ñ†Ğ¸Ñ", f"{max_exposure_pct:.0f}%/{MAX_CONCENTRATION_PCT}%",
                "âœ… OK" if conc_ok else "ğŸ”´ ĞŸĞ Ğ•Ğ’Ğ«Ğ¨Ğ•ĞĞ",
                delta_color="normal" if conc_ok else "inverse"
            )
        
        # Warnings
        warnings_found = False
        for coin, data in sorted_coins:
            if data['total'] >= MAX_COIN_EXPOSURE:
                st.error(
                    f"ğŸš¨ **{coin}** Ğ² {data['total']} Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸ÑÑ… (Ğ»Ğ¸Ğ¼Ğ¸Ñ‚: {MAX_COIN_EXPOSURE}). "
                    f"ĞŸÑ€Ğ¸ Ğ¾Ğ±Ğ²Ğ°Ğ»Ğµ {coin} Ğ½Ğ° 10% Ğ’Ğ¡Ğ• {data['total']} Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾ÑÑ‚Ñ€Ğ°Ğ´Ğ°ÑÑ‚! "
                    f"**Ğ—Ğ°ĞºÑ€Ğ¾Ğ¹Ñ‚Ğµ {data['total'] - MAX_COIN_EXPOSURE + 1} Ğ½Ğ°Ğ¸Ğ¼ĞµĞ½ĞµĞµ Ğ¿Ñ€Ğ¸Ğ±Ñ‹Ğ»ÑŒĞ½ÑƒÑ.**")
                warnings_found = True
            elif data['total'] >= 2:
                st.warning(f"âš ï¸ **{coin}** Ğ² {data['total']} Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸ÑÑ… ({data['long']}L/{data['short']}S)")
                warnings_found = True
            
            if data['long'] > 0 and data['short'] > 0:
                st.error(
                    f"ğŸš¨ **{coin}** ĞšĞĞĞ¤Ğ›Ğ˜ĞšĞ¢: LONGÃ—{data['long']} + SHORTÃ—{data['short']} "
                    f"Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾ â†’ Ñ…ĞµĞ´Ğ¶Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ÑĞ°Ğ¼Ğ¾Ğ³Ğ¾ ÑĞµĞ±Ñ!")
                warnings_found = True
        
        if not warnings_found:
            st.success("âœ… ĞŸĞ¾Ñ€Ñ‚Ñ„ĞµĞ»ÑŒ Ğ² Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ°Ñ… Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ğ¾Ğ².")
        
        # === 5. Position P&L table ===
        st.markdown("#### ğŸ“ˆ P&L Ğ¿Ğ¾ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸ÑĞ¼")
        pnl_data = []
        for pos in open_positions:
            pair = f"{pos['coin1']}/{pos['coin2']}"
            mon = mon_cache.get(pos['id'])
            if mon:
                hours_in = pos.get('hours_in', 0)
                pnl_data.append({
                    '#': pos['id'],
                    'ĞŸĞ°Ñ€Ğ°': pair,
                    'Dir': pos['direction'],
                    'Entry Z': f"{mon['z_entry']:+.2f}",
                    'Now Z': f"{mon['z_now']:+.2f}",
                    'P&L': f"{mon['pnl_pct']:+.3f}%",
                    'Zâ†’0': 'âœ…' if mon['z_towards_zero'] else 'âŒ',
                    'Ğ§Ğ°ÑĞ¾Ğ²': f"{hours_in:.1f}",
                    'Ğ¡Ğ¸Ğ³Ğ½Ğ°Ğ»': (mon.get('exit_signal') or 'â€”')[:35],
                })
        if pnl_data:
            st.dataframe(pd.DataFrame(pnl_data), use_container_width=True, hide_index=True)
        
        # === 6. Quick recommendations ===
        st.markdown("#### ğŸ’¡ Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸")
        recs = []
        
        # Find worst position
        worst_pos = None
        worst_pnl = 0
        for pos in open_positions:
            mon = mon_cache.get(pos['id'])
            if mon and mon['pnl_pct'] < worst_pnl:
                worst_pnl = mon['pnl_pct']
                worst_pos = pos
        
        if worst_pos and worst_pnl < -0.5:
            recs.append(f"ğŸ”´ Ğ¥ÑƒĞ´ÑˆĞ°Ñ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ: **{worst_pos['coin1']}/{worst_pos['coin2']}** "
                       f"(P&L={worst_pnl:+.3f}%). Ğ Ğ°ÑÑĞ¼Ğ¾Ñ‚Ñ€Ğ¸Ñ‚Ğµ Ğ·Ğ°ĞºÑ€Ñ‹Ñ‚Ğ¸Ğµ.")
        
        # Exit signals
        exits = []
        for pos in open_positions:
            mon = mon_cache.get(pos['id'])
            if mon and mon.get('exit_signal'):
                exits.append(f"**{pos['coin1']}/{pos['coin2']}**: {mon['exit_signal'][:40]}")
        if exits:
            recs.append(f"ğŸ“ Ğ¡Ğ¸Ğ³Ğ½Ğ°Ğ»Ñ‹ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ°: " + "; ".join(exits))
        
        # Concentration
        for coin, data in sorted_coins:
            if data['total'] >= 3:
                # Find least profitable pair with this coin
                least_profit = None
                least_pnl = 999
                for pos in open_positions:
                    if pos['coin1'] == coin or pos['coin2'] == coin:
                        mon = mon_cache.get(pos['id'])
                        if mon and mon['pnl_pct'] < least_pnl:
                            least_pnl = mon['pnl_pct']
                            least_profit = pos
                if least_profit:
                    recs.append(
                        f"âš ï¸ Ğ”Ğ»Ñ ÑĞ½Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ ÑĞºÑĞ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ Ğ½Ğ° **{coin}** Ğ·Ğ°ĞºÑ€Ğ¾Ğ¹Ñ‚Ğµ "
                        f"**{least_profit['coin1']}/{least_profit['coin2']}** "
                        f"(Ğ½Ğ°Ğ¸Ğ¼ĞµĞ½ĞµĞµ Ğ¿Ñ€Ğ¸Ğ±Ñ‹Ğ»ÑŒĞ½Ğ°Ñ: {least_pnl:+.3f}%)")
        
        if recs:
            for r in recs:
                st.markdown(r)
        else:
            st.success("âœ… ĞĞµÑ‚ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¹. ĞŸĞ¾Ñ€Ñ‚Ñ„ĞµĞ»ÑŒ Ğ²Ñ‹Ğ³Ğ»ÑĞ´Ğ¸Ñ‚ Ğ·Ğ´Ğ¾Ñ€Ğ¾Ğ²Ñ‹Ğ¼.")
        
        # === 7. Portfolio Download ===
        st.markdown("#### ğŸ“¥ Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ğ¿Ğ¾Ñ€Ñ‚Ñ„ĞµĞ»Ñ")
        portfolio_rows = []
        for pos in open_positions:
            mon = mon_cache.get(pos['id'])
            portfolio_rows.append({
                '#': pos['id'],
                'ĞŸĞ°Ñ€Ğ°': f"{pos['coin1']}/{pos['coin2']}",
                'Dir': pos['direction'],
                'TF': pos.get('timeframe', '4h'),
                'Entry_Z': pos.get('entry_z', 0),
                'Current_Z': mon['z_now'] if mon else '',
                'Entry_HR': pos.get('entry_hr', 0),
                'Current_HR': mon['hr_now'] if mon else '',
                'HR_Drift_%': round(abs(mon['hr_now'] - pos.get('entry_hr', 0)) / max(0.0001, pos.get('entry_hr', 0)) * 100, 1) if mon else '',
                'P&L_%': round(mon['pnl_pct'], 4) if mon else '',
                'Hours_In': round(mon['hours_in'], 1) if mon else '',
                'HL_hours': round(mon.get('halflife_hours', 0), 1) if mon else '',
                'Hurst': round(mon.get('hurst', 0.5), 3) if mon else '',
                'P-value': round(mon.get('pvalue', 1.0), 4) if mon else '',
                'Z_Toward_Zero': mon.get('z_towards_zero', '') if mon else '',
                'Exit_Signal': (mon.get('exit_signal', '') or '')[:40] if mon else '',
                'Entry_Time': pos.get('entry_time', ''),
                'Entry_P1': pos.get('entry_price1', ''),
                'Entry_P2': pos.get('entry_price2', ''),
                'Now_P1': mon.get('price1_now', '') if mon else '',
                'Now_P2': mon.get('price2_now', '') if mon else '',
            })
        if portfolio_rows:
            portfolio_df = pd.DataFrame(portfolio_rows)
            csv_portfolio = portfolio_df.to_csv(index=False)
            
            dl1, dl2 = st.columns(2)
            with dl1:
                st.download_button("ğŸ“¥ ĞŸĞ¾Ñ€Ñ‚Ñ„ĞµĞ»ÑŒ (CSV)", csv_portfolio,
                    f"portfolio_{now_msk().strftime('%Y%m%d_%H%M')}.csv", "text/csv",
                    key="portfolio_csv_btn")
            with dl2:
                # Also auto-save to disk
                try:
                    import os
                    os.makedirs("position_exports", exist_ok=True)
                    pf_path = f"position_exports/portfolio_{now_msk().strftime('%Y%m%d_%H%M')}.csv"
                    portfolio_df.to_csv(pf_path, index=False)
                    st.caption(f"ğŸ’¾ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾: {pf_path}")
                except Exception:
                    pass

# Auto refresh
if auto_refresh:
    time.sleep(120)
    st.rerun()

st.divider()
st.caption("""
ĞšĞ°Ğº Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ:
1. ĞĞ°Ğ¹Ğ´Ğ¸ ğŸŸ¢ Ğ’Ğ¥ĞĞ” Ğ² ÑĞºÑ€Ğ¸Ğ½ĞµÑ€Ğµ
2. Ğ¡ĞºĞ¾Ğ¿Ğ¸Ñ€ÑƒĞ¹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ: Coin1, Coin2, Direction, Z, HR, Ñ†ĞµĞ½Ñ‹
3. Ğ’Ğ²ĞµĞ´Ğ¸ Ğ² Ñ„Ğ¾Ñ€Ğ¼Ñƒ ÑĞ»ĞµĞ²Ğ° â†’ "Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ñ†ĞµĞ½Ñ‹ + Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ"
4. ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€ Ğ¿Ğ¾ĞºĞ°Ğ¶ĞµÑ‚ ĞºĞ¾Ğ³Ğ´Ğ° Ğ·Ğ°ĞºÑ€Ñ‹Ğ²Ğ°Ñ‚ÑŒ + Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ´Ğ¸Ñ‚ ĞµÑĞ»Ğ¸ Ğ¿Ğ°Ñ€Ğ° Ğ¿Ğ¾Ñ‚ĞµÑ€ÑĞ»Ğ° ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾
""")
